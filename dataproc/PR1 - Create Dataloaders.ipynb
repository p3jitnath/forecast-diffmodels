{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c1fe0f-7ae4-4e2d-89bc-55f742c4ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import skimage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18fdc2d5-4d34-4952-8e6f-e6d31f2497e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01b0d2e-2c24-4f70-a9a9-2010d2ee9200",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/vol/bitbucket/pn222/satellite/dataloader/64_PRP/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12668dd4-942e-43a8-b920-2a00946aa830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout = open(f'DL_PRP_LOG_{datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\")}.log','wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a0f70c-ebcb-4e18-93c7-1d441502c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclones_path = \"./list_of_cyclones.xlsx\"\n",
    "df = pd.read_excel(cyclones_path)\n",
    "df = df.drop('Unnamed: 8', axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c71a46-09ca-4edc-8b84-767e9cc9bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_stub_already_present(dest_folder, stub):\n",
    "    stubs = [x.split('/')[-1] for x in glob.glob(dest_folder+\"*.dat\")]\n",
    "    if stub in stubs: \n",
    "        print(f\"Present: {stub}\", flush=True)\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7afc1252-ccab-4e5d-9c97-949a49f6ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cyclone(idx):       \n",
    "    row = df.iloc[idx]\n",
    "    region = row[\"Region\"]\n",
    "    name = row[\"Name\"]\n",
    "    cyclone = Cyclone(region, name)\n",
    "    cyclone.load_era5()\n",
    "    \n",
    "    o_size = 64 ; n_size = 128\n",
    "    data_loader = CycloneDataLoader(mode=\"tp\")\n",
    "    \n",
    "    region = region_to_abbv[region]\n",
    "    name = name.replace(' ', '').lower()\n",
    "    filename = f\"{region}_{name}.dat\"\n",
    "    \n",
    "    if is_stub_already_present(BASE_DIR, filename):\n",
    "        return\n",
    "    \n",
    "    print(f\"[{name.upper()}] Processing dataloader.\", flush=True)\n",
    "    \n",
    "    for satmap_idx in tqdm(range(cyclone.metadata['count'])):\n",
    "        ir108_fn = cyclone.metadata['satmaps'][satmap_idx]['ir108_fn']\n",
    "        ir108_scn = cyclone.get_ir108_data(ir108_fn)    \n",
    "        img = ir108_scn.to_numpy() ; \n",
    "        img = transform_make_sq_image(img)    \n",
    "          \n",
    "        img_o = skimage.transform.resize(img, (o_size, o_size), anti_aliasing=True)\n",
    "        img_o = torch.from_numpy(img_o).unsqueeze(0)\n",
    "        img_n = torch.zeros((1, n_size, n_size))\n",
    "        \n",
    "        era5_idx = cyclone.metadata['satmaps'][satmap_idx]['era5_idx']\n",
    "        era5 = cyclone.get_era5_data(era5_idx, gfs=True)\n",
    "        era5 = skimage.transform.resize(era5, (3, o_size, o_size), anti_aliasing=True)\n",
    "        era5 = torch.from_numpy(era5)\n",
    "        \n",
    "        img_o = torch.cat([img_o, era5]).unsqueeze(0)\n",
    "\n",
    "        era5_tp = cyclone.get_era5_tp_data(era5_idx)\n",
    "        era5_tp = skimage.transform.resize(era5_tp, (o_size, o_size), anti_aliasing=True)\n",
    "        era5_tp = torch.from_numpy(era5_tp).unsqueeze(0)\n",
    "\n",
    "        if torch.isnan(img_o.sum()) or torch.isnan(img_n.sum()) or torch.isnan(era5_tp.sum()):\n",
    "            print(f\"[NAN]\\t{region}\\t{name}\\t{satmap_idx}\", flush=True)\n",
    "            continue\n",
    "        \n",
    "        data_loader.add_image(img_o, img_n, era5_tp)\n",
    "    \n",
    "    with open(f'{BASE_DIR}{filename}', 'wb') as data_file:\n",
    "        pickle.dump(data_loader, data_file)\n",
    "    \n",
    "    print(f\"[{name.upper()}] Completed processing dataloader.\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e2f7ec6-17a1-4654-96ec-92ee6ca9039e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 117/117 [04:45<00:00,  2.44s/it]\n",
      "100%|█████████████████████████████████████████| 137/137 [05:26<00:00,  2.38s/it]\n",
      "100%|█████████████████████████████████████████| 139/139 [05:37<00:00,  2.43s/it]\n",
      "100%|█████████████████████████████████████████| 141/141 [05:37<00:00,  2.40s/it]\n",
      "100%|█████████████████████████████████████████| 158/158 [06:05<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "idx = list(range(5))\n",
    "\n",
    "pool = Pool(cpu_count())\n",
    "fetch_cyclone_func = partial(fetch_cyclone)\n",
    "results = pool.map(fetch_cyclone_func, idx)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0092a0e-bcca-4776-9502-42357c31f67c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
